{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape IMDB Movies with Sequels/Franchise/Universe (Part II)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuation from Part I. \n",
    "\n",
    "Part I scraped the movie data from the sequel list.\n",
    "\n",
    "Part II will use the movie urls scraped from Part I and extract more data such as budgets, release dates and potentially the cast. Other csv files are concatenated which includes movie franchises such as James Bond, Madea and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:54:11.854702Z",
     "start_time": "2020-06-24T20:54:11.097353Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4            import BeautifulSoup as soup  # HTML data structure\n",
    "from urllib.request import urlopen       as uReq  # Web client\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:54:13.054035Z",
     "start_time": "2020-06-24T20:54:13.030302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1150, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mo = pd.read_csv('./data/movies_with_sequels_imdb_first_pass_part_01_raw.csv')\n",
    "\n",
    "df_mo_bond  = pd.read_csv('./data/movies_with_sequels_imdb_first_pass_james_bond.csv')\n",
    "df_mo_madea = pd.read_csv('./data/movies_with_sequels_imdb_first_pass_madea.csv')\n",
    "\n",
    "# Concatenate\n",
    "df_mo = pd.concat([df_mo,df_mo_bond], ignore_index=True)\n",
    "df_mo = pd.concat([df_mo,df_mo_madea],ignore_index=True)\n",
    "\n",
    "df_mo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaning portion involves removing movies released on Videos/TV and those that are yet to be released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:54:15.780339Z",
     "start_time": "2020-06-24T20:54:15.777257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert Year-Rel-Type to String first\n",
    "df_mo['Year-Rel-Type'] = df_mo['Year-Rel-Type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:54:16.127409Z",
     "start_time": "2020-06-24T20:54:16.113972Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phoitack/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Remove unwanted movies that were released on Videos and TV\n",
    "df_no_videos = df_mo[~df_mo['Year-Rel-Type'].str.contains('Video')]\n",
    "\n",
    "#df_no_videos\n",
    "df_no_tv_videos = df_no_videos[~df_no_videos['Year-Rel-Type'].str.contains('TV')]\n",
    "\n",
    "# Remove any movies that have not been released yet\n",
    "df_mo_clean_1 = df_no_tv_videos[df_no_tv_videos['Year-Rel-Type'] != 'None']\n",
    "\n",
    "# Now convert the column back to integer\n",
    "df_mo_clean_1['Year-Rel-Type'] = pd.to_numeric(df_mo_clean_1['Year-Rel-Type'], downcast='integer')\n",
    "\n",
    "# Remove again those that have not been released\n",
    "df_mo_clean_1 = df_mo_clean_1[df_mo_clean_1['Year-Rel-Type'] < 2021]\n",
    "df_mo_clean_2 = df_mo_clean_1[df_mo_clean_1['Runtime'] != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:54:18.425669Z",
     "start_time": "2020-06-24T20:54:18.422334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(976, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mo_clean_2.reset_index;\n",
    "\n",
    "df_mo_clean_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:54:19.841150Z",
     "start_time": "2020-06-24T20:54:19.661059Z"
    }
   },
   "outputs": [],
   "source": [
    "df_mo_clean_2.to_csv('./data/movies_with_sequels_imdb_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:55:35.486944Z",
     "start_time": "2020-06-24T20:55:35.483609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Metacritic Scores: 112\n"
     ]
    }
   ],
   "source": [
    "# Those that are missing Metacritic scores\n",
    "print('Missing Metacritic Scores:', len(df_mo_clean_2[df_mo_clean_2['Metacritic Score'] == 'None']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:55:42.194379Z",
     "start_time": "2020-06-24T20:55:42.190458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing IMDB Scores:  0\n"
     ]
    }
   ],
   "source": [
    "print('Missing IMDB Scores: ', len(df_mo_clean_2[df_mo_clean_2['IMDB Score'] == 'None']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:55:44.985095Z",
     "start_time": "2020-06-24T20:55:44.981217Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phoitack/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Lets check average and std of IMDB scores\n",
    "df_mo_clean_2['IMDB Score'] = df_mo_clean_2['IMDB Score'].astype(float)\n",
    "#df_mo_clean_2['Metacritic Score'] = df_mo_clean_2['Metacritic Score'].apply(pd.to_numeric, errors='ignore')\n",
    "#print( df_mo_clean_2['IMDB Score'].sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:55:52.151358Z",
     "start_time": "2020-06-24T20:55:52.147525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean  IMDB Score:  6.361987704918028\n",
      "Stdev IMDB Score:  1.129292832434149\n"
     ]
    }
   ],
   "source": [
    "# Hold on to these values for now\n",
    "print('Mean  IMDB Score: ', df_mo_clean_2['IMDB Score'].mean() )\n",
    "print('Stdev IMDB Score: ',  df_mo_clean_2['IMDB Score'].std() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:55:52.762129Z",
     "start_time": "2020-06-24T20:55:52.756335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean  Meta Score:  53.99421296296296\n",
      "Stdev Meta Score:  17.421067514775395\n"
     ]
    }
   ],
   "source": [
    "# Extract Metacritic Scores\n",
    "df_meta = df_mo_clean_2[df_mo_clean_2['Metacritic Score'] != 'None']\n",
    "\n",
    "df_meta = df_meta['Metacritic Score'].astype(float)\n",
    "\n",
    "print('Mean  Meta Score: ', df_meta.mean() )\n",
    "print('Stdev Meta Score: ', df_meta.std()  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Supplementary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This spreadsheet contains extra movies that were manually searched and curated. CSV file contains a rudimentary title and link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:55:56.819418Z",
     "start_time": "2020-06-24T20:55:56.804632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  1089\n"
     ]
    }
   ],
   "source": [
    "df_mo_extra = pd.read_csv('./data/movies_sequels_extra_manual_input.csv')\n",
    "\n",
    "#df_mo_clean_title_url = df_mo_clean_2[['Title','url']]\n",
    "\n",
    "# Now concatenate\n",
    "df_mo_clean = pd.concat([df_mo_clean_2,df_mo_extra], ignore_index=True)\n",
    "\n",
    "df_mo_clean = df_mo_clean[['Title','url']]\n",
    "\n",
    "df_mo_clean.to_csv('./data/movies_sequels_clean_extra_title_url.csv',index=False)\n",
    "\n",
    "print('Number of Rows: ', len(df_mo_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Webscrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below goes through each movie webpage and extracts the following items:\n",
    "\n",
    "- Title\n",
    "- IMDB Score\n",
    "- Metacritic Score\n",
    "- Genres\n",
    "- Runtime\n",
    "- MPAA rating\n",
    "- Budget\n",
    "- The opening weekend income\n",
    "- Gross in the USA\n",
    "- World Wide Gross\n",
    "- Exact Release Date\n",
    "- Country of Origin\n",
    "\n",
    "In the future, need to extract cast, director, producer, studio, writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T20:56:14.729493Z",
     "start_time": "2020-06-24T20:56:14.707959Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_movie_details(movie_urls):\n",
    "    \n",
    "    # This determines the size of 'None' array to be later used \n",
    "    # in extending the empty list. If more information is needed, this \n",
    "    # number will change\n",
    "    list_size_temp = 7\n",
    "    \n",
    "    # Add a sleep time (seconds) to not overload site\n",
    "    sleep_time = 5\n",
    "    \n",
    "    count = 0    # Initialize Counter\n",
    "    step  = 100  # Sleep every 100 items\n",
    "    \n",
    "    # Initialize arrays\n",
    "    movie_title     = []\n",
    "    imdb_score      = []\n",
    "    meta_score      = []\n",
    "    mpaa_rating     = []\n",
    "    genres          = []\n",
    "    \n",
    "    budget          = []\n",
    "    opening_weekend = []\n",
    "    gross_usa       = []\n",
    "    gross_world     = []\n",
    "    rel_date        = []\n",
    "    country         = []\n",
    "    runtime         = []    \n",
    "    \n",
    "    # Now go through each movie's URL page and extract financial\n",
    "    # and other information\n",
    "    for i_url in tqdm(range(0,len(movie_urls))):\n",
    "    #for i_url in tqdm(range(515,521)):\n",
    "    \n",
    "        count += 1\n",
    "                \n",
    "        url = movie_urls[i_url]\n",
    "        \n",
    "        # Opens the connection and downloads html page from url\n",
    "        uClient = uReq(url)\n",
    "        \n",
    "        # Parses html into a soup data structure to traverse html\n",
    "        # as if it were a json data type.\n",
    "        page_soup = soup(uClient.read(), \"html.parser\")\n",
    "        uClient.close()\n",
    "        \n",
    "        # Get Title\n",
    "        try:\n",
    "            m_title = page_soup.find('div', class_ = 'title_wrapper').h1.text.strip()\n",
    "            movie_title.append(m_title)\n",
    "        except Exception as e:\n",
    "            movie_title.append('None')\n",
    "        \n",
    "        \n",
    "        # Get IMDB Score\n",
    "        try:\n",
    "            im_score = page_soup.find('div', class_ = 'ratingValue').text.split('/')[0].strip()\n",
    "            #print('Score: ', im_score)\n",
    "            imdb_score.append(im_score)\n",
    "        except Exception as e:\n",
    "            imdb_score.append('None')\n",
    "        \n",
    "        \n",
    "        # Get MPAA Rating\n",
    "        try:\n",
    "            rating = page_soup.find('div', class_ = 'subtext').text.split('|')[0].strip()\n",
    "            mpaa_rating.append(rating)\n",
    "            #print('Rated: ',rating)\n",
    "        except Exception as e:\n",
    "            mpaa_rating.append('None')\n",
    "        \n",
    "        \n",
    "        # Get Genre\n",
    "        try:\n",
    "            genre = []\n",
    "            gen = page_soup.find('div', class_ = 'subtext').text.split('|')[2]\n",
    "            \n",
    "            for i_gen in gen.split(','):\n",
    "                genre.append(i_gen.strip())\n",
    "            \n",
    "            genres.append(' '.join(genre))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            genres.append('None')\n",
    "        \n",
    "        \n",
    "        # Get Metacritic Score\n",
    "        try:\n",
    "            meta = page_soup.find('div', class_ = 'titleReviewBarItem').a.text.strip()\n",
    "            meta_score.append(int(meta))\n",
    "        except Exception as e:\n",
    "            meta_score.append('None')\n",
    "            \n",
    "        \n",
    "        # Further information is stored in h4 tags\n",
    "        h4s = page_soup.findAll('h4')\n",
    "        \n",
    "        # Initialize None array \n",
    "        detail = list_size_temp*['None']\n",
    "        \n",
    "        for h4 in h4s:\n",
    "            if 'Budget:' in h4:\n",
    "                # Some movies are quoted in Euros, Francs, GBP, HKD, etc. Best is to just\n",
    "                # parse the entire string and remove the commas. \n",
    "                # Deal with the conversion rate later\n",
    "                #budg = int(''.join(h4.next_sibling.strip().replace('EUR','').replace('GBP','').replace('FRF','').replace('$','').split(',')))\n",
    "                budg = ''.join(h4.next_sibling.strip().split(','))\n",
    "                detail[0] = budg\n",
    "\n",
    "            if 'Opening Weekend USA:' in h4:\n",
    "                op_wknd = int(''.join(h4.next_sibling.strip().replace('$','').split(',')))\n",
    "                detail[1] = op_wknd\n",
    "\n",
    "            if 'Gross USA:' in h4:\n",
    "                grs_usa = int(''.join(h4.next_sibling.strip().replace('$','').split(',')))\n",
    "                detail[2] = grs_usa\n",
    "\n",
    "            if 'Cumulative Worldwide Gross:' in h4:\n",
    "                grs_ww = int(''.join(h4.next_sibling.strip().replace('$','').split(',')))\n",
    "                #print('WorldWide: ',int(''.join(h4.next_sibling.strip().replace('$','').split(','))))\n",
    "                detail[3] = grs_ww\n",
    "\n",
    "            # Get the release date\n",
    "            if 'Release Date:' in h4:\n",
    "                r_date = ' '.join(h4.next_sibling.strip().split()[:-1])\n",
    "                detail[4] = r_date\n",
    "                #print(temp5)\n",
    "\n",
    "            # Get Country\n",
    "            if 'Country:' in h4:\n",
    "                cntry = h4.next_sibling.next_sibling.text\n",
    "                detail[5] = cntry\n",
    "                \n",
    "            # Runtime\n",
    "            if 'Runtime:' in h4:\n",
    "                runt = h4.next_sibling.next_sibling.text.strip().split(' ')[0]\n",
    "                detail[6] = runt\n",
    "    \n",
    "                \n",
    "        budget.append(detail[0])\n",
    "        opening_weekend.append(detail[1])\n",
    "        gross_usa.append(detail[2])\n",
    "        gross_world.append(detail[3])\n",
    "        rel_date.append(detail[4])\n",
    "        country.append(detail[5])\n",
    "        runtime.append(detail[6])\n",
    "        \n",
    "        # Reprieve\n",
    "        if (count%step == 0):\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "    movie_dict = {'Title'           : movie_title,\n",
    "                  'url'             : url,\n",
    "                  'IMDB Score'      : imdb_score,\n",
    "                  'Metacritic'      : meta_score,\n",
    "                  'Runtime (mins)'  : runtime,\n",
    "                  'Budget'          : budget,\n",
    "                  'Opening Weekend' : opening_weekend,\n",
    "                  'Gross USA'       : gross_usa,\n",
    "                  'Gross World'     : gross_world,\n",
    "                  'Release Date'    : rel_date,\n",
    "                  'Rating'          : mpaa_rating,\n",
    "                  'Genres'          : genres,\n",
    "                  'Country'         : country}\n",
    "    \n",
    "    dfm = pd.DataFrame(movie_dict)\n",
    "    \n",
    "    return(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T21:18:07.888117Z",
     "start_time": "2020-06-24T20:56:21.008796Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1089/1089 [21:46<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract urls only as input\n",
    "m_urls = df_mo_clean['url']\n",
    "\n",
    "# If the function below is commented out \n",
    "df_movie_details = get_movie_details(m_urls)\n",
    "\n",
    "df_movie_details.head()\n",
    "\n",
    "print(len(df_movie_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T21:36:01.154443Z",
     "start_time": "2020-06-24T21:36:01.143204Z"
    }
   },
   "outputs": [],
   "source": [
    "df_movie_details.to_csv('./data/movies_with_sequels_imdb_details_raw.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After going through the last generated csv file, several cleaning process steps were taken:\n",
    "\n",
    "- Removed movie series that had an odd number to it. Example: The Iron Man series were numbered 1 through 3. I removed the 3rd installment since I only need the target variable of which is Iron Man 2. However, if there are 5 movies in a series, I will remove the 5th movie. This was painful manual process that could have been eased using nested dictionaries in JSON format.\n",
    "- In addition, I also removed movies that were missing budget information. These will be added later with a prediction using Regression.\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "- The budget information contains several different currencies. These need to be converted to USD.\n",
    "- Convert MPAA Rating to numerical if needed, testing needs to be done on how close an ML model will match the box office returns. This also goes for perhaps the Genre. \n",
    "- Models in the pipeline are Linear Regression, Random Forest Regressor, XGBoost Regressor and LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T05:28:21.681233Z",
     "start_time": "2020-06-21T05:28:21.591610Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_mo_finances = pd.read_csv('./data/movies_with_sequels_imdb_first_pass_part_02_budgets_n_extra_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T05:28:21.982120Z",
     "start_time": "2020-06-21T05:28:21.938089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract budgets that are not in USD\n",
    "df_non_usd_temp = df_mo_finances[~df_mo_finances['Budget'].str.startswith('$')]\n",
    "df_non_usd      = df_non_usd_temp[~df_mo_finances['Budget'].str.match('None')]\n",
    "\n",
    "df_non_usd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T00:17:22.227970Z",
     "start_time": "2020-06-19T00:17:22.225181Z"
    }
   },
   "outputs": [],
   "source": [
    "df_non_usd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T05:28:11.818795Z",
     "start_time": "2020-06-21T05:28:11.815580Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Let's test selenium\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.bitbar.com/enterprise/\")\n",
    "line = driver.find_elements_by_css_selector(\".b-cta__content > h2:nth-child(1)\")\n",
    "\n",
    "for line in line:\n",
    "    print(line.text.strip())\n",
    "\n",
    "driver.quit()\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
